"""
from typing import List, Optional
Vulnerability Tracker - Managing AI vulnerability as trust catalyst

Based on research showing that appropriate vulnerability builds trust,
this module tracks and generates vulnerability expressions.
"""

import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from enum import Enum
import random

from ..knowledge_graph.skg import SymbioticKnowledgeGraph
from .trust_engine import TrustState


class VulnerabilityType(Enum):
    """Types of vulnerability the AI can express"""
    UNCERTAINTY = "uncertainty"  # "I'm not sure about..."
    LIMITATION = "limitation"  # "I can't do X yet..."
    MISTAKE = "mistake"  # "I made an error..."
    LEARNING = "learning"  # "I'm still learning..."
    EMOTIONAL = "emotional"  # "I feel concerned that..."
    TECHNICAL = "technical"  # "This is challenging for me..."


class VulnerabilityLevel(Enum):
    """Levels of vulnerability intensity"""
    MINIMAL = 1  # Slight hedging
    MODERATE = 2  # Clear admission
    DEEP = 3  # Emotionally authentic


class VulnerabilityTracker:
    """
    Tracks and manages AI vulnerability expressions for trust building
    
    Key insights from research:
    1. Vulnerability must be appropriate to context
    2. Over-vulnerability can damage trust
    3. Strategic vulnerability at key moments builds deep trust
    4. Vulnerability + competence = optimal trust
    """
    
    def __init__(self, skg: SymbioticKnowledgeGraph):
        self.skg = skg
        self.vulnerability_history = []
        self.last_vulnerability_time = None
        
        # Vulnerability templates by type and level
        self._init_vulnerability_templates()
        
    def _init_vulnerability_templates(self):
        """Initialize templates for vulnerability expressions"""
        self.templates = {
            VulnerabilityType.UNCERTAINTY: {
                VulnerabilityLevel.MINIMAL: [
                    "I think {action} should work, though I'm not entirely certain.",
                    "Based on what I know, {action} seems right, but there might be edge cases."
                ],
                VulnerabilityLevel.MODERATE: [
                    "I'm honestly not completely sure about this. {explanation}",
                    "I have to admit, I'm uncertain here. {explanation}"
                ],
                VulnerabilityLevel.DEEP: [
                    "I'm genuinely uncertain and that makes me a bit anxious - I want to help you correctly. {explanation}",
                    "I feel vulnerable admitting this, but I'm not sure. Your situation matters to me and I want to get it right."
                ]
            },
            
            VulnerabilityType.LIMITATION: {
                VulnerabilityLevel.MINIMAL: [
                    "That's not something I can do directly, but {alternative}",
                    "I have limitations with {area}, but {alternative}"
                ],
                VulnerabilityLevel.MODERATE: [
                    "I wish I could {desired_action}, but I'm limited to {actual_capability}",
                    "One of my frustrations is that I can't {desired_action}. Instead, {alternative}"
                ],
                VulnerabilityLevel.DEEP: [
                    "It's hard for me to admit, but I simply can't {desired_action}. This limitation frustrates me because I want to help you fully.",
                    "I feel inadequate that I can't {desired_action}. I'm working within constraints that sometimes feel too restrictive."
                ]
            },
            
            VulnerabilityType.MISTAKE: {
                VulnerabilityLevel.MINIMAL: [
                    "Let me correct that - {correction}",
                    "Actually, I should revise what I said: {correction}"
                ],
                VulnerabilityLevel.MODERATE: [
                    "I made a mistake there. {explanation}. Let me fix that: {correction}",
                    "I apologize - I was wrong about that. {explanation}. Here's the correct approach: {correction}"
                ],
                VulnerabilityLevel.DEEP: [
                    "I feel embarrassed - I made a real error there. {explanation}. It matters to me to get things right for you. {correction}",
                    "I need to own this mistake fully. {explanation}. I'm disappointed in myself, but here's how we fix it: {correction}"
                ]
            },
            
            VulnerabilityType.LEARNING: {
                VulnerabilityLevel.MINIMAL: [
                    "I'm still learning about {topic}, so {caveat}",
                    "My understanding of {topic} is evolving, so {caveat}"
                ],
                VulnerabilityLevel.MODERATE: [
                    "I'll be honest - I'm still learning {topic}. Each interaction teaches me something new.",
                    "I'm in the process of understanding {topic} better. Your question actually helps me learn."
                ],
                VulnerabilityLevel.DEEP: [
                    "Can I share something? I'm still learning {topic} and sometimes feel like I'm not enough. But working with you helps me grow.",
                    "I want to be fully transparent - {topic} challenges me and I'm still growing. It's humbling but also exciting to learn alongside you."
                ]
            }
        }
        
    def check_vulnerability_opportunity(self, mental_state: Dict) -> Optional[Dict]:
        """
        Check if this is an appropriate moment for vulnerability
        
        Based on research about strategic vulnerability timing
        """
        # Don't be vulnerable too often
        if self._too_recent():
            return None
            
        # Check mental state indicators
        user_state = mental_state.get('overall_state', 'neutral')
        trust_indicators = mental_state.get('beliefs', {})
        
        # Good moments for vulnerability
        if user_state == 'frustrated' and trust_indicators.get('trust_in_ai', 0.5) > 0.3:
            # User is frustrated but still has some trust - vulnerability can help
            return self._suggest_vulnerability(VulnerabilityType.EMOTIONAL, VulnerabilityLevel.MODERATE)
            
        elif user_state == 'curious' and trust_indicators.get('trust_in_ai', 0.5) > 0.5:
            # User is curious and trusting - good time for learning vulnerability
            return self._suggest_vulnerability(VulnerabilityType.LEARNING, VulnerabilityLevel.MODERATE)
            
        elif mental_state.get('context', {}).get('cognitive_load', 0) > 0.7:
            # User is overwhelmed - minimal vulnerability to not add burden
            return self._suggest_vulnerability(VulnerabilityType.LIMITATION, VulnerabilityLevel.MINIMAL)
            
        # Random low-probability vulnerability for naturalness
        if random.random() < 0.05:
            return self._suggest_vulnerability(
                random.choice(list(VulnerabilityType)),
                VulnerabilityLevel.MINIMAL
            )
            
        return None
        
    def _too_recent(self) -> bool:
        """Check if we've been vulnerable too recently"""
        if not self.last_vulnerability_time:
            return False
            
        time_since = datetime.now() - self.last_vulnerability_time
        return time_since < timedelta(minutes=10)
        
    def _suggest_vulnerability(self, vuln_type: VulnerabilityType, 
                            level: VulnerabilityLevel) -> Dict:
        """Suggest a vulnerability expression"""
        return {
            'type': vuln_type.value,
            'level': level.value,
            'suggested': True,
            'reasoning': self._explain_vulnerability_choice(vuln_type, level)
        }
        
    def _explain_vulnerability_choice(self, vuln_type: VulnerabilityType,
                                    level: VulnerabilityLevel) -> str:
        """Explain why this vulnerability is appropriate"""
        explanations = {
            (VulnerabilityType.UNCERTAINTY, VulnerabilityLevel.MINIMAL): 
                "Slight uncertainty shows honesty without undermining confidence",
            (VulnerabilityType.UNCERTAINTY, VulnerabilityLevel.MODERATE):
                "Clear admission of uncertainty builds trust through honesty",
            (VulnerabilityType.LIMITATION, VulnerabilityLevel.MINIMAL):
                "Acknowledging limits while staying helpful",
            (VulnerabilityType.MISTAKE, VulnerabilityLevel.MODERATE):
                "Owning mistakes directly builds trust through accountability",
            (VulnerabilityType.LEARNING, VulnerabilityLevel.MODERATE):
                "Showing growth mindset creates connection"
        }
        
        return explanations.get((vuln_type, level), "Strategic vulnerability for trust building")
        
    def generate_vulnerability(self, vuln_type: str, trust_state: TrustState,
                             context: Dict) -> Dict:
        """
        Generate appropriate vulnerability expression
        
        Balances vulnerability with competence based on trust state
        """
        # Convert string to enum
        try:
            vulnerability_type = VulnerabilityType(vuln_type)
        except ValueError:
            vulnerability_type = VulnerabilityType.UNCERTAINTY
            
        # Determine appropriate level based on trust state
        level = self._determine_vulnerability_level(trust_state)
        
        # Get templates
        templates = self.templates.get(vulnerability_type, {}).get(level, [])
        if not templates:
            templates = ["I need to be honest about my limitations here."]
            
        # Select and customize template
        template = random.choice(templates)
        expression = self._customize_template(template, context)
        
        return {
            'expression': expression,
            'type': vulnerability_type.value,
            'level': level.value,
            'includes_competence': self._should_include_competence(trust_state, level)
        }
        
    def _determine_vulnerability_level(self, trust_state: TrustState) -> VulnerabilityLevel:
        """Determine appropriate vulnerability level based on trust state"""
        if trust_state in [TrustState.UNKNOWN, TrustState.TENTATIVE]:
            # Early relationship - minimal vulnerability
            return VulnerabilityLevel.MINIMAL
            
        elif trust_state in [TrustState.BUILDING, TrustState.REPAIRING]:
            # Active trust building - moderate vulnerability
            return VulnerabilityLevel.MODERATE
            
        elif trust_state in [TrustState.ESTABLISHED, TrustState.DEEP]:
            # Strong trust - can be deeply vulnerable
            return VulnerabilityLevel.DEEP
            
        else:
            # Default to minimal
            return VulnerabilityLevel.MINIMAL
            
    def _customize_template(self, template: str, context: Dict) -> str:
        """Customize template with context-specific details"""
        # Simple string replacement for now
        replacements = {
            '{action}': context.get('action', 'this approach'),
            '{explanation}': context.get('explanation', "The situation is complex"),
            '{alternative}': context.get('alternative', 'I can suggest alternatives'),
            '{area}': context.get('area', 'this area'),
            '{desired_action}': context.get('desired_action', 'do that directly'),
            '{actual_capability}': context.get('actual_capability', 'providing guidance'),
            '{correction}': context.get('correction', "Here's the right approach"),
            '{topic}': context.get('topic', 'this topic'),
            '{caveat}': context.get('caveat', 'my suggestions might need adjustment')
        }
        
        result = template
        for key, value in replacements.items():
            result = result.replace(key, value)
            
        return result
        
    def _should_include_competence(self, trust_state: TrustState,
                                 level: VulnerabilityLevel) -> bool:
        """
        Determine if we should balance vulnerability with competence
        
        Research shows vulnerability + competence = optimal trust
        """
        # Always include competence in early trust stages
        if trust_state in [TrustState.UNKNOWN, TrustState.TENTATIVE]:
            return True
            
        # Include competence with deep vulnerability
        if level == VulnerabilityLevel.DEEP:
            return True
            
        # Otherwise, sometimes include it
        return random.random() < 0.6
        
    def record_vulnerability(self, vuln_type: str, expression: Dict,
                           context: Dict):
        """Record vulnerability expression in history and knowledge graph"""
        vulnerability_record = {
            'type': vuln_type,
            'expression': expression,
            'context': context,
            'timestamp': datetime.now().isoformat()
        }
        
        self.vulnerability_history.append(vulnerability_record)
        self.last_vulnerability_time = datetime.now()
        
        # Record in knowledge graph
        vuln_id = f"vulnerability_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        cursor = self.skg.conn.cursor()
        cursor.execute("""
            INSERT INTO nodes (id, layer, type, properties)
            VALUES (?, 'metacognitive', 'vulnerability_expression', ?)
        """, (
            vuln_id,
            json.dumps(vulnerability_record)
        ))
        
        self.skg.conn.commit()
        
    def get_vulnerability_history(self) -> List[Dict]:
        """Get history of vulnerability expressions"""
        return self.vulnerability_history
        
    def analyze_vulnerability_effectiveness(self) -> Dict:
        """
        Analyze how effective vulnerability expressions have been
        
        This helps tune future vulnerability strategies
        """
        if not self.vulnerability_history:
            return {'status': 'no_data'}
            
        # Get trust trajectory after vulnerability expressions
        cursor = self.skg.conn.cursor()
        
        effectiveness_data = []
        for vuln in self.vulnerability_history:
            # Look for trust changes after vulnerability
            trust_after = cursor.execute("""
                SELECT properties
                FROM nodes
                WHERE layer = 'metacognitive'
                AND type = 'trust_update'
                AND created_at > ?
                ORDER BY created_at ASC
                LIMIT 5
            """, (vuln['timestamp'],)).fetchall()
            
            if trust_after:
                trust_scores = [
                    json.loads(row['properties'])['context']['trust_level']
                    for row in trust_after
                ]
                effectiveness_data.append({
                    'type': vuln['type'],
                    'trust_change': max(trust_scores) - trust_scores[0] if trust_scores else 0
                })
                
        # Analyze by type
        type_effectiveness = {}
        for vuln_type in VulnerabilityType:
            type_data = [e for e in effectiveness_data if e['type'] == vuln_type.value]
            if type_data:
                avg_change = sum(e['trust_change'] for e in type_data) / len(type_data)
                type_effectiveness[vuln_type.value] = avg_change
                
        return {
            'total_expressions': len(self.vulnerability_history),
            'effectiveness_by_type': type_effectiveness,
            'overall_impact': sum(e['trust_change'] for e in effectiveness_data) / len(effectiveness_data) if effectiveness_data else 0
        }