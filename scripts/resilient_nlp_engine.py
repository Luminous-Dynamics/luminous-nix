#!/usr/bin/env python3
"""
from typing import List
Resilient NLP Engine
====================

Multi-tiered natural language processing that adapts to available resources.
"""

import os
import sys
import json
import time
import subprocess
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from abc import ABC, abstractmethod

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from nix_knowledge_engine import NixOSKnowledgeEngine


@dataclass
class NLPCapabilities:
    """Describes what an NLP tier can do"""
    name: str
    accuracy: float
    requirements: str
    features: List[str]
    limitations: List[str]


class NLPTier(ABC):
    """Abstract base class for NLP tiers"""
    
    @abstractmethod
    def initialize(self) -> bool:
        """Try to initialize this tier"""
        pass
    
    @abstractmethod
    def process(self, text: str) -> Dict:
        """Process natural language input"""
        pass
    
    @abstractmethod
    def get_capabilities(self) -> NLPCapabilities:
        """Get tier capabilities"""
        pass


class MistralLLMTier(NLPTier):
    """Tier 1: Local LLM for deep understanding"""
    
    def __init__(self):
        self.model = None
        self.model_path = os.path.expanduser("~/.cache/mistral-7b-instruct")
        
    def initialize(self) -> bool:
        """Check if Mistral model is available"""
        try:
            # Check if model exists
            if not os.path.exists(self.model_path):
                return False
                
            # Try to load a small test (in real implementation)
            # For now, just check if ollama is available
            result = subprocess.run(
                ["which", "ollama"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                print("‚ú® Mistral-7B LLM available for deep understanding!")
                return True
                
        except Exception as e:
            print(f"Mistral initialization failed: {e}")
            
        return False
        
    def process(self, text: str) -> Dict:
        """Process with LLM understanding"""
        # In real implementation, would call ollama
        # For now, return enhanced mock
        
        intent_map = {
            "install": ["install", "get", "need", "want"],
            "update": ["update", "upgrade", "patch"],
            "fix": ["broken", "not working", "help", "fix"],
            "search": ["find", "search", "look for", "where"]
        }
        
        text_lower = text.lower()
        detected_intent = "unknown"
        confidence = 0.95
        
        for intent, keywords in intent_map.items():
            if any(keyword in text_lower for keyword in keywords):
                detected_intent = intent
                break
                
        # Extract entities with "deep understanding"
        entities = []
        if "firefox" in text_lower:
            entities.append({"type": "package", "value": "firefox"})
        if "wifi" in text_lower or "internet" in text_lower:
            entities.append({"type": "service", "value": "network"})
            
        return {
            "intent": detected_intent,
            "confidence": confidence,
            "entities": entities,
            "original_text": text,
            "tier": "mistral-llm",
            "reasoning": "Deep semantic understanding with context"
        }
        
    def get_capabilities(self) -> NLPCapabilities:
        return NLPCapabilities(
            name="Mistral-7B Local LLM",
            accuracy=0.95,
            requirements="6GB RAM, GPU preferred",
            features=[
                "Deep semantic understanding",
                "Context awareness",
                "Complex query handling",
                "Multi-turn conversation",
                "Reasoning about intent"
            ],
            limitations=[
                "Requires significant resources",
                "Slower on CPU-only systems"
            ]
        )


class EnhancedPatternTier(NLPTier):
    """Tier 2: Advanced pattern matching with context"""
    
    def __init__(self):
        self.knowledge_engine = None
        self.context_window = []
        
    def initialize(self) -> bool:
        """Initialize enhanced pattern engine"""
        try:
            self.knowledge_engine = NixOSKnowledgeEngine()
            print("üß† Enhanced pattern engine initialized!")
            return True
        except Exception as e:
            print(f"Enhanced pattern initialization failed: {e}")
            return False
            
    def process(self, text: str) -> Dict:
        """Process with enhanced patterns"""
        # Use the knowledge engine
        intent_data = self.knowledge_engine.extract_intent(text)
        
        # Enhance with context if available
        confidence = 0.85
        if self.context_window:
            # Boost confidence if consistent with context
            confidence = 0.90
            
        return {
            "intent": intent_data.get("action", "unknown"),
            "confidence": confidence,
            "entities": [{"type": "query", "value": text}],
            "original_text": text,
            "tier": "enhanced-pattern",
            "package": intent_data.get("package"),
            "reasoning": "Pattern matching with NixOS knowledge base"
        }
        
    def get_capabilities(self) -> NLPCapabilities:
        return NLPCapabilities(
            name="Enhanced Pattern Engine",
            accuracy=0.85,
            requirements="512MB RAM",
            features=[
                "Intent recognition",
                "Package name extraction",
                "Common phrase understanding",
                "NixOS-specific patterns"
            ],
            limitations=[
                "Limited to known patterns",
                "No complex reasoning"
            ]
        )


class BasicPatternTier(NLPTier):
    """Tier 3: Basic keyword matching"""
    
    def __init__(self):
        self.keywords = {
            "install": ["install", "get", "add"],
            "update": ["update", "upgrade"],
            "remove": ["remove", "delete", "uninstall"],
            "search": ["search", "find", "list"],
            "help": ["help", "how", "what"]
        }
        
    def initialize(self) -> bool:
        """Always available"""
        print("üìù Basic pattern matching available (fallback mode)")
        return True
        
    def process(self, text: str) -> Dict:
        """Basic keyword matching"""
        text_lower = text.lower()
        detected_intent = "help"  # Default
        confidence = 0.70
        
        for intent, keywords in self.keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                detected_intent = intent
                break
                
        return {
            "intent": detected_intent,
            "confidence": confidence,
            "entities": [],
            "original_text": text,
            "tier": "basic-pattern",
            "reasoning": "Simple keyword matching"
        }
        
    def get_capabilities(self) -> NLPCapabilities:
        return NLPCapabilities(
            name="Basic Pattern Matching",
            accuracy=0.70,
            requirements="150MB RAM",
            features=[
                "Keyword detection",
                "Basic commands",
                "Fast response"
            ],
            limitations=[
                "No context understanding",
                "Limited vocabulary",
                "May misunderstand complex queries"
            ]
        )


class ResilientNLPEngine:
    """Multi-tiered NLP engine with graceful degradation"""
    
    def __init__(self):
        self.tiers = [
            MistralLLMTier(),
            EnhancedPatternTier(),
            BasicPatternTier()
        ]
        self.active_tier = None
        self.available_tiers = []
        self.performance_history = []
        
    def initialize(self):
        """Initialize best available tier"""
        print("\nüîç Initializing NLP Engine...")
        print("=" * 50)
        
        for tier in self.tiers:
            if tier.initialize():
                self.available_tiers.append(tier)
                if self.active_tier is None:
                    self.active_tier = tier
                    
        if not self.available_tiers:
            raise RuntimeError("No NLP tiers available!")
            
        print(f"\n‚úÖ NLP Engine ready with {len(self.available_tiers)} tier(s)")
        print(f"Primary: {self.active_tier.get_capabilities().name}")
        
    def process_with_fallback(self, text: str) -> Dict:
        """Process text with automatic fallback"""
        errors = []
        
        for tier in self.available_tiers:
            try:
                start_time = time.time()
                result = tier.process(text)
                elapsed = time.time() - start_time
                
                # Track performance
                self.performance_history.append({
                    "tier": tier.__class__.__name__,
                    "time": elapsed,
                    "success": True
                })
                
                # Add metadata
                result["processing_time"] = elapsed
                result["tier_capabilities"] = tier.get_capabilities()
                
                return result
                
            except Exception as e:
                errors.append(f"{tier.__class__.__name__}: {e}")
                if tier != self.available_tiers[-1]:
                    print(f"‚ö†Ô∏è  {tier.__class__.__name__} failed, trying next tier...")
                    
        # All tiers failed
        raise RuntimeError(f"All NLP tiers failed: {errors}")
        
    def get_status_message(self) -> str:
        """Get user-friendly status message"""
        if not self.active_tier:
            return "‚ùå No language understanding available"
            
        caps = self.active_tier.get_capabilities()
        
        if isinstance(self.active_tier, MistralLLMTier):
            return "üéì I have advanced understanding today! Feel free to ask complex questions."
        elif isinstance(self.active_tier, EnhancedPatternTier):
            return "üí≠ I have good understanding of NixOS commands. Ask me anything!"
        else:
            return "üìù I have basic understanding. Please use simple, direct commands."
            
    def explain_capabilities(self) -> str:
        """Explain current capabilities to user"""
        if not self.active_tier:
            return "I'm not able to understand commands right now."
            
        caps = self.active_tier.get_capabilities()
        
        msg = f"**Current Language Understanding: {caps.name}**\n\n"
        msg += f"‚úÖ What I can do:\n"
        for feature in caps.features:
            msg += f"  ‚Ä¢ {feature}\n"
            
        if caps.limitations:
            msg += f"\n‚ö†Ô∏è  Current limitations:\n"
            for limitation in caps.limitations:
                msg += f"  ‚Ä¢ {limitation}\n"
                
        msg += f"\nüìä Accuracy: {caps.accuracy * 100:.0f}%"
        
        return msg
        
    def get_performance_report(self) -> Dict:
        """Get performance statistics"""
        if not self.performance_history:
            return {"message": "No performance data yet"}
            
        # Calculate stats per tier
        tier_stats = {}
        for entry in self.performance_history:
            tier = entry["tier"]
            if tier not in tier_stats:
                tier_stats[tier] = {
                    "count": 0,
                    "total_time": 0,
                    "failures": 0
                }
            
            tier_stats[tier]["count"] += 1
            if entry["success"]:
                tier_stats[tier]["total_time"] += entry["time"]
            else:
                tier_stats[tier]["failures"] += 1
                
        # Format report
        report = {
            "active_tier": self.active_tier.__class__.__name__,
            "available_tiers": len(self.available_tiers),
            "tier_statistics": {}
        }
        
        for tier, stats in tier_stats.items():
            if stats["count"] > 0:
                avg_time = stats["total_time"] / (stats["count"] - stats["failures"])
                report["tier_statistics"][tier] = {
                    "average_response_time": f"{avg_time:.3f}s",
                    "total_requests": stats["count"],
                    "failure_rate": f"{(stats['failures'] / stats['count']) * 100:.1f}%"
                }
                
        return report


def demonstrate_nlp_tiers():
    """Demonstrate the multi-tiered NLP system"""
    
    # Create engine
    engine = ResilientNLPEngine()
    engine.initialize()
    
    print("\n" + engine.get_status_message())
    print("\n" + engine.explain_capabilities())
    
    # Test queries
    test_queries = [
        "I need to install Firefox to check my email",
        "My WiFi isn't working",
        "Update my system",
        "How do I use NixOS?",
        "install zoom"
    ]
    
    print("\nüß™ Testing Natural Language Understanding")
    print("=" * 50)
    
    for query in test_queries:
        print(f"\nüí¨ Query: '{query}'")
        
        try:
            result = engine.process_with_fallback(query)
            
            print(f"üéØ Intent: {result['intent']} (confidence: {result['confidence'] * 100:.0f}%)")
            print(f"‚ö° Processed by: {result['tier']}")
            print(f"‚è±Ô∏è  Response time: {result['processing_time']:.3f}s")
            
            if result.get('package'):
                print(f"üì¶ Package detected: {result['package']}")
                
        except Exception as e:
            print(f"‚ùå Error: {e}")
            
    # Show performance report
    print("\nüìä Performance Report")
    print("=" * 50)
    report = engine.get_performance_report()
    print(json.dumps(report, indent=2))


if __name__ == "__main__":
    demonstrate_nlp_tiers()