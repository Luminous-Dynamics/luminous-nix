#!/usr/bin/env python3
"""
üïâÔ∏è Main CLI for Luminous Nix

This is the official CLI that uses the unified backend.
All the power, properly organized.
"""

import argparse
import asyncio
import logging
import os
import sys

# Configure logging to suppress info messages in normal operation
logging.basicConfig(
    level=logging.WARNING,  # Only show warnings and errors
    format="%(message)s",  # Simple format for user-facing messages
)

# Add the src directory to the Python path
sys.path.insert(
    0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "src")
)

from luminous_nix.core.backend import (
    NixForHumanityBackend,
    get_backend,
)
from luminous_nix.api.schema import Context, Request, Response
from luminous_nix.service_simple import LuminousNixService, ServiceOptions
# Note: Plugins are not yet integrated into the backend
# from nix_for_humanity.plugins.config_generator import (
#     ConfigGeneratorPlugin,
#     SmartSearchPlugin,
# )

# Import search command handler
try:
    from luminous_nix.cli.search_command import handle_search_in_query
    SEARCH_AVAILABLE = True
except ImportError:
    SEARCH_AVAILABLE = False

# Import pragmatic learning system
try:
    from luminous_nix.learning.pragmatic_learning import PragmaticLearningSystem

    LEARNING_AVAILABLE = True
except ImportError:
    LEARNING_AVAILABLE = False

# Import Tree-sitter commands (standalone to avoid Click dependency)
try:
    import importlib.util
    spec = importlib.util.spec_from_file_location(
        "tree_sitter_commands_standalone",
        os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            "src", "luminous_nix", "cli", "tree_sitter_commands_standalone.py"
        )
    )
    tree_sitter_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(tree_sitter_module)
    TreeSitterCommands = tree_sitter_module.TreeSitterCommands
    TREE_SITTER_AVAILABLE = True
except Exception as e:
    TREE_SITTER_AVAILABLE = False
    # Log error for debugging (will only show with --debug)
    logging.debug(f"Tree-sitter module not available: {e}")


async def handle_tree_sitter_query(query: str, execute: bool):
    """Handle Tree-sitter related queries"""
    commands = TreeSitterCommands()
    query_lower = query.lower()
    
    # Analyze project
    if "analyze" in query_lower and ("project" in query_lower or "code" in query_lower):
        # Extract path from query (default to current directory)
        import re
        path_match = re.search(r'["\']([^"\']+)["\']', query)
        path = path_match.group(1) if path_match else "."
        
        result = commands.analyze_project(path)
        if result["success"]:
            print(result["message"])
            return 0
        else:
            print(f"Error: {result.get('error', 'Analysis failed')}")
            return 1
    
    # Migrate shell script
    elif "migrate" in query_lower or "convert" in query_lower:
        import re
        from pathlib import Path
        # Look for .sh file in query
        script_match = re.search(r'(\S+\.sh)', query)
        if script_match:
            script = script_match.group(1)
            # Check if file exists (handle both relative and absolute paths)
            if not Path(script).exists():
                # Try in /tmp if it's a temp file
                if script.startswith("tmp"):
                    script = f"/tmp/{script}"
            
            if Path(script).exists():
                result = commands.migrate_script(script)
                if result["success"]:
                    print(result["message"])
                    return 0
                else:
                    print(f"Error: {result.get('message', 'Migration failed')}")
                    return 1
            else:
                print(f"Error: Script file '{script}' not found")
                return 1
        else:
            print("Please specify a shell script to migrate (e.g., 'migrate setup.sh')")
            return 1
    
    # Suggest packages
    elif "suggest" in query_lower or "package for" in query_lower:
        # Extract description after "for" or "suggest"
        if "package for" in query_lower:
            description = query_lower.split("package for")[-1].strip()
        else:
            description = query_lower.replace("suggest packages", "").replace("suggest", "").strip()
        
        if description:
            result = commands.suggest_packages(description)
            if result["success"]:
                print(result["message"])
                if result["suggestions"]:
                    print("\nüí° Suggested packages:")
                    for pkg in result["suggestions"]:
                        print(f"  - {pkg}")
                return 0
            else:
                print(f"Error: {result.get('error')}")
                return 1
    
    # Generate config
    elif "generate" in query_lower and "config" in query_lower:
        template = "minimal"  # Default
        if "desktop" in query_lower:
            template = "desktop"
        elif "development" in query_lower or "dev" in query_lower:
            template = "development"
        
        result = commands.generate_config(template)
        if result["success"]:
            print(result["message"])
            print("\n" + result["config"][:500] + "...")
            return 0
        else:
            print(f"Error: {result.get('error')}")
            return 1
    
    # If we couldn't handle it, fall back to regular processing
    return None


class BackendAdapter:
    """Adapter to make the backend work with the CLI's async expectations"""
    
    def __init__(self, backend):
        self.backend = backend
        self.dry_run = True
    
    async def initialize(self):
        """Initialize the backend (no-op for now)"""
        pass
    
    async def execute(self, query: str, context: Context) -> Response:
        """Execute a query through the backend"""
        # Create a request object
        request = Request(
            query=query,
            context={"dry_run": self.dry_run, "execute": not self.dry_run}
        )
        
        # Process synchronously (backend.process is sync)
        response = self.backend.process(request)
        
        # Ensure response has expected attributes
        if not hasattr(response, 'output'):
            response.output = getattr(response, 'text', '')
        if not hasattr(response, 'error'):
            response.error = None
        if not hasattr(response, 'suggestions'):
            response.suggestions = []
        if not hasattr(response, 'success'):
            response.success = response.error is None
        
        return response
    
    async def cleanup(self):
        """Cleanup (no-op for now)"""
        pass


def setup_backend(dry_run=True):
    """Setup the backend with adapter"""
    # Use the new service layer instead of direct backend
    options = ServiceOptions(
        execute=not dry_run,
        interface="cli",
        verbose=os.getenv("DEBUG") == "1"
    )
    service = LuminousNixService(options)
    
    # For backward compatibility, wrap in adapter
    # (will remove this once we fully migrate)
    backend = get_backend()
    adapter = BackendAdapter(backend)
    adapter.dry_run = dry_run
    adapter._service = service  # Store service for potential future use
    
    return adapter


async def execute_query(
    query: str, execute: bool = False, enable_learning: bool = True, output_format: str = "text"
):
    """Execute a natural language query with optional learning"""
    # Handle help queries specially
    if query.lower() in ["help", "help me", "what can you do", "how do i use this"]:
        show_help()
        return 0
    
    # Check for search queries (high priority)
    if SEARCH_AVAILABLE and handle_search_in_query(query):
        return 0
    
    # Check for Tree-sitter related queries
    if TREE_SITTER_AVAILABLE:
        tree_keywords = [
            "analyze project", "analyze code", "scan project", "analyze my",
            "migrate", "convert script", "shell to nix",
            "suggest package", "package for",
            "generate config", "config template"
        ]
        
        query_lower = query.lower()
        for keyword in tree_keywords:
            if keyword in query_lower:
                logging.info(f"Tree-sitter handling query: {query}")
                result = await handle_tree_sitter_query(query, execute)
                if result is not None:
                    return result
                # If Tree-sitter couldn't handle it, continue with regular processing
                break
    else:
        logging.debug("Tree-sitter not available")

    # Initialize learning system if available and enabled
    learning = None
    if LEARNING_AVAILABLE and enable_learning:
        try:
            learning = PragmaticLearningSystem("cli_user")

            # Check for learned aliases
            alias_suggestion = learning.suggest_alias(query)
            if alias_suggestion:
                print(f"üí° {alias_suggestion}")
        except Exception:
            pass  # Learning is optional, don't fail on errors

    # Determine if this might be a long operation
    long_operations = ["install", "update", "rebuild", "search", "generate", "build"]
    is_long = any(op in query.lower() for op in long_operations)

    # Show progress for long operations if in a terminal
    spinner = None
    if is_long and sys.stdout.isatty():
        try:
            from luminous_nix.ui.progress import Spinner

            spinner = Spinner("Processing your request")
            spinner.start()
        except ImportError:
            pass  # Progress indicator not available

    try:
        backend = setup_backend(dry_run=not execute)
        await backend.initialize()

        context = Context()  # Context doesn't take user_id
        result = await backend.execute(query, context)
        
        # Handle JSON output format
        if output_format in ["json", "brief"]:
            import json
            output_data = {
                "query": query,
                "success": result.success,
                "output": result.output,
                "error": result.error,
                "executed": execute,
            }
            if output_format == "json":
                print(json.dumps(output_data, indent=2))
            else:  # brief
                if result.success:
                    print(result.output.strip())
                else:
                    print(f"Error: {result.error}")
            return 0 if result.success else 1

        # Track learning if enabled (only for text output)
        if learning:
            try:
                learning.observe_command(query, result.success, result.error)

                # Suggest next command if successful
                if result.success:
                    next_suggestion = learning.suggest_next_command(query)
                    if next_suggestion:
                        print(f"\nüîÆ {next_suggestion}")

                # Suggest error fix if failed
                elif result.error:
                    error_fix = learning.suggest_error_fix(result.error)
                    if error_fix:
                        print(f"\nüí° {error_fix}")
            except Exception:
                pass  # Learning failures shouldn't break the command

        # Stop spinner before displaying result
        if spinner:
            if result.success:
                spinner.stop("‚úì Complete")
            else:
                spinner.stop("‚úó Failed")

        # Display result
        if result.success:
            print(result.output)
        else:
            print(f"Error: {result.error}")
            if result.suggestions:
                print("\nSuggestions:")
                for suggestion in result.suggestions:
                    print(f"  ‚Ä¢ {suggestion}")

        await backend.cleanup()
        return 0 if result.success else 1

    except Exception as e:
        if spinner:
            spinner.stop("‚úó Error")
        raise


async def interactive_mode():
    """Interactive REPL mode"""
    print("üïâÔ∏è Luminous Nix - Interactive Mode")
    print("Enter natural language commands. Type 'exit' to leave.")
    print("Prefix with '!' to execute for real (not dry-run).")
    print()

    backend = setup_backend(dry_run=True)
    await backend.initialize()
    context = Context()  # Context doesn't take user_id

    while True:
        try:
            query = input("nix> ").strip()

            if query.lower() in ["exit", "quit"]:
                break

            if not query:
                continue

            # Check for execution prefix
            if query.startswith("!"):
                query = query[1:].strip()
                backend.dry_run = False
            else:
                backend.dry_run = True

            result = await backend.execute(query, context)

            if result.output:
                print(result.output)
            if result.error:
                print(f"Error: {result.error}")

        except KeyboardInterrupt:
            print("\nGoodbye!")
            break
        except Exception as e:
            print(f"Error: {e}")

    await backend.cleanup()


def show_help():
    """Show comprehensive help information"""
    help_text = """
üïâÔ∏è Luminous Nix - Natural Language NixOS Interface

USAGE:
    ask-nix [OPTIONS] <QUERY>
    ask-nix --interactive

EXAMPLES:
    # Install a package (dry-run by default)
    ask-nix "install firefox"

    # Execute for real
    ask-nix --execute "install firefox"

    # Search for packages
    ask-nix "search for markdown editor"

    # Generate configurations
    ask-nix "web server with nginx and postgresql"

    # Development environments
    ask-nix "development environment with python and rust"

    # Interactive mode
    ask-nix --interactive

FEATURES:
    ‚Ä¢ Natural language understanding
    ‚Ä¢ Smart package discovery
    ‚Ä¢ Configuration generation
    ‚Ä¢ Safe dry-run by default
    ‚Ä¢ 10x-1500x faster with native API

TIPS:
    ‚Ä¢ Use simple, natural language
    ‚Ä¢ Preview operations with dry-run
    ‚Ä¢ Use --execute only when ready
    ‚Ä¢ Try --debug for troubleshooting

For more information, visit: https://github.com/Luminous-Dynamics/nix-for-humanity
"""
    print(help_text)


def main():
    """Main entry point"""
    # Check for alias subcommand first
    if len(sys.argv) > 1 and sys.argv[1] == "alias":
        from luminous_nix.cli.alias_command import handle_alias_command
        handle_alias_command(sys.argv[2:])
        return 0
    
    parser = argparse.ArgumentParser(
        description="Natural language interface to NixOS",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="Use 'ask-nix --help-full' for comprehensive help",
    )
    parser.add_argument("query", nargs="*", help="Natural language query")
    parser.add_argument(
        "--execute", "-e", action="store_true", help="Execute for real (not dry-run)"
    )
    parser.add_argument(
        "--interactive", "-i", action="store_true", help="Interactive mode"
    )
    parser.add_argument(
        "--debug", "-d", action="store_true", help="Enable debug logging"
    )
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        default=None,
        help="Set logging level",
    )
    parser.add_argument("--log-file", type=str, help="Log to file instead of console")
    parser.add_argument(
        "--help-full", action="store_true", help="Show comprehensive help with examples"
    )
    parser.add_argument(
        "--no-learning",
        action="store_true",
        help="Disable learning and personalization",
    )
    parser.add_argument(
        "--show-learning",
        action="store_true",
        help="Show what the system has learned about you",
    )
    parser.add_argument(
        "--delete-learning-data",
        action="store_true",
        help="Delete all learned data and reset",
    )
    parser.add_argument(
        "--json",
        action="store_true",
        help="Output in JSON format for programmatic use",
    )
    parser.add_argument(
        "--format",
        choices=["text", "json", "brief"],
        default="text",
        help="Output format (default: text)",
    )

    args = parser.parse_args()

    # Configure logging using our logging config system
    from luminous_nix.core.logging_config import setup_logging

    if args.debug:
        setup_logging(debug=True)
    elif args.log_level:
        setup_logging(level=args.log_level)
    else:
        # Default: only warnings and errors to console
        setup_logging(level="WARNING")

    # Add file handler if specified
    if args.log_file:
        import logging.handlers

        from luminous_nix.core.logging_config import get_logging_config

        file_handler = logging.handlers.RotatingFileHandler(
            args.log_file, maxBytes=10 * 1024 * 1024, backupCount=3  # 10MB
        )
        file_handler.setFormatter(
            logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        )
        get_logging_config().add_handler("", file_handler)

    # Show comprehensive help if requested
    if args.help_full:
        show_help()
        return 0

    # Handle learning management
    if args.show_learning:
        if LEARNING_AVAILABLE:
            learning = PragmaticLearningSystem("cli_user")
            print(learning.export_learnings())
        else:
            print("Learning system not available")
        return 0

    if args.delete_learning_data:
        if LEARNING_AVAILABLE:
            learning = PragmaticLearningSystem("cli_user")
            print(learning.delete_all_data())
        else:
            print("Learning system not available")
        return 0

    if args.interactive:
        return asyncio.run(interactive_mode())
    elif args.query:
        query = " ".join(args.query)
        enable_learning = not args.no_learning
        output_format = "json" if args.json else args.format
        return asyncio.run(execute_query(query, args.execute, enable_learning, output_format))
    else:
        parser.print_help()
        return 0


if __name__ == "__main__":
    sys.exit(main())
